"""
Comprehensive example: Multi-site LLM Engineer job search.
Shows how to search across multiple job platforms for LLM roles.
"""

import asyncio
from src.scrapers.multi_site_llm_scraper import create_multi_site_llm_scraper
from src.database.job_vector_store import JobVectorStore
from dotenv import load_dotenv

# Load environment variables
load_dotenv()


async def demonstrate_multi_site_architecture():
    """Show the multi-site scraper architecture and current status."""
    print("ğŸŒ Multi-Site LLM Scraper Architecture")
    print("=" * 45)
    
    # Create multi-site scraper
    scraper = create_multi_site_llm_scraper()
    
    # Show site status
    print("ğŸ“Š Supported Job Sites:")
    site_status = scraper.get_site_status()
    
    for site, status in site_status.items():
        impl_status = "âœ… Ready" if status["implemented"] else "â³ Coming Soon"
        enabled_status = "ğŸŸ¢ Enabled" if status["enabled"] else "ğŸ”´ Disabled"
        
        print(f"\nğŸŒ {site.title()}")
        print(f"   Status: {impl_status}")
        print(f"   Search: {enabled_status}")
        print(f"   Priority: #{status['priority']}")
        print(f"   Expected Results: {status['expected_results']}")
        print(f"   Specialties: {', '.join(status['specialties'])}")
    
    print(f"\nğŸ’¡ Implementation Roadmap:")
    print(f"   âœ… ZipRecruiter - Currently working")
    print(f"   ğŸš§ Indeed - High priority (most job volume)")
    print(f"   ğŸš§ LinkedIn - Medium priority (high quality)")
    print(f"   ğŸš§ Glassdoor - Low priority (salary info)")
    print(f"   ğŸš§ AngelList - Low priority (startup focus)")


async def search_current_sites():
    """Search using currently implemented sites."""
    print(f"\nğŸ” Multi-Site LLM Job Search")
    print("=" * 35)
    
    # Create scraper
    scraper = create_multi_site_llm_scraper(strict_mode=False)
    
    print("ğŸ¯ Searching for LLM Engineer jobs across all available sites...")
    print("ğŸ“ Location: Houston, TX")
    print("ğŸšï¸ Mode: General (all experience levels)")
    
    try:
        # Perform multi-site search
        results = await scraper.search_all_sites(
            location="Houston, TX",
            max_pages_per_site=2,
            seniority_level=None  # All levels
        )
        
        # Results are automatically printed by the scraper
        # But we can also access the data programmatically
        
        if results.total_jobs_found > 0:
            print(f"\nğŸ“ˆ Detailed Analysis:")
            print(f"   ğŸ¯ Search efficiency: {results.total_jobs_found} jobs in {results.search_duration:.1f}s")
            print(f"   ğŸ† Best site: {results.best_site.title()}")
            
            # Show unique companies
            companies = set(job.company for job in results.all_jobs)
            print(f"   ğŸ¢ Unique companies: {len(companies)}")
            if len(companies) <= 5:
                print(f"      Companies: {', '.join(companies)}")
            
            # Show remote work distribution
            remote_jobs = len([j for j in results.all_jobs if j.remote_type.value in ['remote', 'hybrid']])
            remote_percentage = remote_jobs / results.total_jobs_found * 100
            print(f"   ğŸ  Remote-friendly: {remote_jobs}/{results.total_jobs_found} ({remote_percentage:.1f}%)")
            
            return results
        else:
            print("âŒ No LLM jobs found!")
            print("ğŸ’¡ This might be because:")
            print("   â€¢ Limited job sites currently implemented")
            print("   â€¢ Strict filtering criteria")
            print("   â€¢ Limited LLM jobs in Houston area")
            print("   â€¢ Scraping issues (rate limiting, etc.)")
            return None
    
    except Exception as e:
        print(f"âŒ Multi-site search failed: {e}")
        import traceback
        traceback.print_exc()
        return None


async def compare_single_vs_multi_site():
    """Compare single-site vs multi-site LLM job searching."""
    print(f"\nâš–ï¸  Single-Site vs Multi-Site Comparison")
    print("=" * 45)
    
    from src.scrapers.llm_engineer_scraper import create_llm_engineer_scraper
    
    # Single-site search (ZipRecruiter only)
    print("1ï¸âƒ£ Single-Site Search (ZipRecruiter only):")
    try:
        single_scraper = create_llm_engineer_scraper()
        single_results = await single_scraper.search_llm_jobs(max_pages=2)
        single_jobs = single_results["jobs"]
        
        print(f"   ğŸ“Š Found: {len(single_jobs)} LLM jobs")
        print(f"   ğŸ¯ Source: ZipRecruiter only")
        
    except Exception as e:
        print(f"   âŒ Single-site search failed: {e}")
        single_jobs = []
    
    # Multi-site search
    print(f"\n2ï¸âƒ£ Multi-Site Search (All available sites):")
    try:
        multi_scraper = create_multi_site_llm_scraper()
        multi_results = await multi_scraper.search_all_sites(max_pages_per_site=2)
        multi_jobs = multi_results.all_jobs
        
        print(f"   ğŸ“Š Found: {len(multi_jobs)} LLM jobs")
        print(f"   ğŸ¯ Sources: {', '.join(multi_results.successful_sites)}")
        
        # Calculate improvement
        if single_jobs:
            improvement = len(multi_jobs) / len(single_jobs)
            print(f"   ğŸ“ˆ Improvement: {improvement:.1f}x more jobs")
        
        # Show source breakdown
        if multi_results.site_results:
            print(f"   ğŸ” Source breakdown:")
            for site, results in multi_results.site_results.items():
                if results.get("status") == "success":
                    jobs_found = results.get("jobs_found", 0)
                    print(f"      â€¢ {site.title()}: {jobs_found} jobs")
        
    except Exception as e:
        print(f"   âŒ Multi-site search failed: {e}")
        multi_jobs = []
    
    # Summary
    print(f"\nğŸ“‹ Comparison Summary:")
    print(f"   Single-site jobs: {len(single_jobs)}")
    print(f"   Multi-site jobs: {len(multi_jobs)}")
    if single_jobs and multi_jobs:
        print(f"   Additional coverage: {len(multi_jobs) - len(single_jobs)} more jobs")


async def store_multi_site_results():
    """Store multi-site LLM job results in vector database."""
    print(f"\nğŸ’¾ Store Multi-Site Results in Vector Database")
    print("=" * 50)
    
    # Perform multi-site search
    scraper = create_multi_site_llm_scraper()
    results = await scraper.search_all_sites(
        location="Houston, TX",
        max_pages_per_site=3
    )
    
    if not results.all_jobs:
        print("âŒ No jobs to store!")
        return
    
    # Store in vector database
    print(f"ğŸ’¾ Storing {len(results.all_jobs)} LLM jobs in vector database...")
    
    try:
        vector_store = JobVectorStore(db_path="./multi_site_llm_db")
        added, failed = vector_store.add_jobs(results.all_jobs)
        
        print(f"âœ… Storage complete:")
        print(f"   ğŸ“¥ Added: {added} jobs")
        print(f"   âŒ Failed: {failed} jobs")
        
        # Test semantic search across all sites
        print(f"\nğŸ” Testing cross-site semantic search...")
        
        test_queries = [
            "transformer neural networks",
            "pytorch machine learning",
            "remote ai engineer",
            "senior llm developer"
        ]
        
        for query in test_queries:
            search_results = vector_store.search_jobs(query, n_results=3)
            
            print(f"\nğŸ“‹ Results for '{query}':")
            for i, result in enumerate(search_results, 1):
                source = result.get('source', 'unknown')
                similarity = result.get('similarity_score', 0)
                print(f"   {i}. {result['title']} ({source}) - {similarity:.2%} match")
        
        print(f"\nğŸ‰ Multi-site LLM jobs are now searchable!")
        print(f"ğŸ“ Database location: ./multi_site_llm_db")
        
    except Exception as e:
        print(f"âŒ Error storing jobs: {e}")


def show_implementation_guide():
    """Show how to implement additional job sites."""
    print(f"\nğŸ› ï¸  Adding New Job Sites - Implementation Guide")
    print("=" * 55)
    
    guide = [
        "1. ğŸ“ Create site-specific scraper:",
        "   â€¢ Inherit from PlaywrightJobScraper",
        "   â€¢ Implement site-specific selectors", 
        "   â€¢ Handle anti-bot measures",
        "   â€¢ Create LLM-optimized filters",
        "",
        "2. ğŸ”§ Add to multi-site scraper:",
        "   â€¢ Add scraper to self.scrapers dict",
        "   â€¢ Configure in self.site_configs",
        "   â€¢ Set priority and expected results",
        "",
        "3. ğŸ§ª Test integration:",
        "   â€¢ Test individual scraper", 
        "   â€¢ Test multi-site integration",
        "   â€¢ Verify deduplication works",
        "",
        "4. ğŸ“Š Site-specific considerations:",
        "   â€¢ Indeed: CAPTCHA, rate limiting, high volume",
        "   â€¢ LinkedIn: Authentication, ToS issues, high quality",
        "   â€¢ Glassdoor: Salary focus, moderate volume",
        "   â€¢ AngelList: Startup focus, equity info"
    ]
    
    for line in guide:
        print(f"   {line}")
    
    print(f"\nğŸ’¡ Implementation Priority:")
    print(f"   ğŸ¥‡ Indeed (highest job volume)")
    print(f"   ğŸ¥ˆ LinkedIn (highest quality)")
    print(f"   ğŸ¥‰ Glassdoor (salary insights)")
    print(f"   4ï¸âƒ£ AngelList (startup roles)")


async def main():
    """Main demo function."""
    print("ğŸ¤– Multi-Site LLM Engineer Job Search Demo")
    print("=" * 50)
    print("This demo shows the architecture for searching LLM jobs")
    print("across multiple job platforms with unified filtering.")
    
    await demonstrate_multi_site_architecture()
    
    # Show current functionality
    results = await search_current_sites()
    
    if results and results.total_jobs_found > 0:
        # Only run additional demos if we found jobs
        await compare_single_vs_multi_site()
        await store_multi_site_results()
    
    show_implementation_guide()
    
    print(f"\nğŸ¯ Next Steps:")
    print(f"   1. Implement Indeed scraper (highest priority)")
    print(f"   2. Implement LinkedIn scraper (high quality)")
    print(f"   3. Add Glassdoor for salary insights")
    print(f"   4. Consider AngelList for startup roles")
    print(f"   5. Add site-specific optimizations")
    
    print(f"\nğŸš€ Current Usage:")
    print(f"   from src.scrapers.multi_site_llm_scraper import create_multi_site_llm_scraper")
    print(f"   scraper = create_multi_site_llm_scraper()")
    print(f"   results = await scraper.search_all_sites()")


if __name__ == "__main__":
    asyncio.run(main())
